# ðŸš€ TIER 1: Production Essentials - Implementation Guide

## Overview

TIER 1 adds production-grade monitoring, logging, security, and error tracking to the OMNI AI Worker platform.

### Features Implemented

âœ… **Prometheus Metrics** - Real-time performance monitoring  
âœ… **Structured Logging** - JSON logs with context tracking  
âœ… **API Authentication** - API key-based auth with tiered access  
âœ… **Rate Limiting** - Prevent abuse with tier-based limits  
âœ… **Sentry Integration** - Automatic error tracking and alerts  

---

## ðŸŽ¯ Quick Start

### 1. Install Dependencies

```bash
cd ai-worker
pip install -r requirements.txt
```

New dependencies added:
- `prometheus-client==0.19.0` - Metrics collection
- `slowapi==0.1.9` - Rate limiting
- `sentry-sdk==1.39.1` - Error tracking
- `psutil==5.9.6` - System metrics

### 2. Configure Environment

```bash
cp .env.example .env
# Edit .env with your values
```

**Required variables:**
```bash
# Sentry (get from https://sentry.io)
SENTRY_DSN=https://your-key@o0.ingest.sentry.io/0

# Authentication
MASTER_API_KEY=your-secure-random-key-here

# Redis (for rate limiting)
REDIS_HOST=localhost  # or Cloud Memorystore IP
REDIS_PORT=6379

# Environment
ENVIRONMENT=production
LOG_LEVEL=INFO
```

### 3. Run Locally

```bash
cd ai-worker
uvicorn main:app --host 0.0.0.0 --port 8080 --reload
```

### 4. Test TIER 1 Features

```bash
cd tests
python tier1_tests.py
```

---

## ðŸ“Š Prometheus Metrics

### Available Metrics

#### Request Metrics
- `api_requests_total` - Total requests by endpoint, method, status
- `api_request_duration_seconds` - Request latency histogram
- `api_active_requests` - Currently processing requests
- `api_errors_total` - Error count by type

#### Model Metrics
- `model_inference_duration_seconds` - Model inference time
- `model_requests_total` - Model calls by type and tenant

#### System Metrics
- `process_memory_bytes` - Memory usage
- `process_cpu_percent` - CPU utilization

#### Cache Metrics
- `cache_hits_total` - Cache hit count
- `cache_misses_total` - Cache miss count

### Accessing Metrics

```bash
# Metrics endpoint (no auth required)
curl http://localhost:8080/metrics

# Example output:
# api_requests_total{endpoint="/predict/revenue-lstm",method="POST",status="200"} 42.0
# api_request_duration_seconds_bucket{endpoint="/predict/revenue-lstm",le="1.0"} 35.0
```

### Grafana Dashboard Setup

1. **Add Prometheus Data Source**:
   - URL: `http://prometheus:9090`
   - Scrape interval: 15s

2. **Import Dashboard**:
   - Use template: `FastAPI Application`
   - Or create custom dashboard with panels:
     - Request Rate: `rate(api_requests_total[5m])`
     - Latency P95: `histogram_quantile(0.95, api_request_duration_seconds_bucket)`
     - Error Rate: `rate(api_errors_total[5m])`
     - Active Requests: `api_active_requests`

3. **Prometheus scrape config**:
```yaml
scrape_configs:
  - job_name: 'omni-ai-worker'
    static_configs:
      - targets: ['ai-worker:8080']
    metrics_path: '/metrics'
    scrape_interval: 15s
```

---

## ðŸ“ Structured Logging

### Log Format

All logs are JSON-formatted for easy parsing:

```json
{
  "timestamp": "2025-11-01T10:30:45.123Z",
  "level": "INFO",
  "message": "LSTM forecast requested",
  "service": "ai-worker",
  "request_id": "abc-123-def-456",
  "tenant_id": "demo-tenant-1",
  "context": {
    "forecast_steps": 30,
    "data_points": 100
  }
}
```

### Using Logger in Code

```python
from utils.structured_logging import get_logger, set_request_context

logger = get_logger(__name__)

# Set request context (done automatically in endpoints)
set_request_context(request_id="abc-123", tenant_id="tenant-1")

# Log messages
logger.info("Operation started", operation="train_model")
logger.warning("High latency detected", latency_ms=2500)
logger.error("Model training failed", error=exception)
```

### Querying Logs in Cloud Logging

```bash
# Filter by request_id
jsonPayload.request_id="abc-123-def-456"

# Filter by tenant
jsonPayload.tenant_id="demo-tenant-1"

# Filter by error level
jsonPayload.level="ERROR"

# Combine filters
jsonPayload.tenant_id="demo-tenant-1" AND jsonPayload.level="ERROR"
```

---

## ðŸ” Authentication & Authorization

### API Key Tiers

| Tier | Rate Limit | Use Case |
|------|-----------|----------|
| Free | 100/minute | Testing, personal projects |
| Pro | 1,000/minute | Production apps, startups |
| Enterprise | 10,000/minute | Large-scale deployments |

### Demo API Keys (for testing)

```python
# Free tier
X-API-Key: demo-free-key-12345

# Pro tier
X-API-Key: demo-pro-key-67890

# Enterprise tier
X-API-Key: demo-enterprise-key-abcdef
```

### Making Authenticated Requests

```bash
# With X-API-Key header
curl -X POST https://your-api.run.app/predict/revenue-lstm \
  -H "X-API-Key: demo-pro-key-67890" \
  -H "Content-Type: application/json" \
  -d '{
    "tenant_id": "my-tenant",
    "time_series": [100, 110, 120, 130],
    "forecast_steps": 5,
    "sequence_length": 3
  }'

# Or with Authorization Bearer
curl -X POST https://your-api.run.app/predict/revenue-lstm \
  -H "Authorization: Bearer demo-pro-key-67890" \
  -H "Content-Type: application/json" \
  -d '...'
```

### Creating New API Keys

```python
from middleware.auth import create_api_key

# Create new API key
api_key = create_api_key(
    tenant_id="customer-123",
    tier="pro",
    name="Production API Key"
)

print(f"API Key: {api_key}")
# Output: omni_pro_abc123def456...
```

### Public Endpoints (No Auth)

These endpoints don't require authentication:
- `/` - Root/info
- `/health` - Health check
- `/metrics` - Prometheus metrics
- `/docs` - API documentation
- `/openapi.json` - OpenAPI schema

---

## âš¡ Rate Limiting

### How It Works

Rate limiting is applied per IP address and respects tier limits:

```python
# In endpoint decorator
@limiter.limit("100/minute")  # Default limit
async def endpoint(request: Request):
    # Actual limit determined by API key tier
    pass
```

### Rate Limit Response

When rate limit exceeded:
```json
{
  "error": "Rate limit exceeded",
  "message": "Too many requests. Please try again later.",
  "retry_after": 45
}
```

HTTP Status: `429 Too Many Requests`

### Rate Limit Headers

Response includes:
```
X-RateLimit-Limit: 1000
X-RateLimit-Remaining: 247
X-RateLimit-Reset: 1698765432
```

### Bypass Rate Limiting (Development)

```bash
# In .env
DEV_MODE=true
ENABLE_RATE_LIMITING=false
```

---

## ðŸ› Sentry Error Tracking

### Setup

1. **Create Sentry Project**:
   - Go to https://sentry.io
   - Create new project (Python/FastAPI)
   - Copy DSN

2. **Configure Environment**:
```bash
SENTRY_DSN=https://abc123@o0.ingest.sentry.io/123456
SENTRY_TRACES_SAMPLE_RATE=0.1  # 10% of transactions
GIT_SHA=v1.0.0  # Or use: $(git rev-parse --short HEAD)
```

3. **Automatic Capture**:
   - All unhandled exceptions
   - HTTP errors (4xx, 5xx)
   - Performance transactions

### Manual Error Capture

```python
from utils.sentry_integration import capture_exception, capture_message

try:
    result = risky_operation()
except Exception as e:
    capture_exception(e, tenant_id="tenant-1", operation="train_model")
    raise

# Capture warning
capture_message("High latency detected", level="warning", latency_ms=3000)
```

### Sentry Features

- **Error Grouping**: Similar errors grouped together
- **Breadcrumbs**: Request flow leading to error
- **Context**: Tenant ID, user ID, request details
- **Stack Traces**: Full Python stack trace
- **Performance**: Slow transaction alerts
- **Releases**: Track errors by deployment version

---

## ðŸ§ª Testing

### Run TIER 1 Tests

```bash
cd tests
python tier1_tests.py
```

Tests include:
1. âœ… Public endpoints (no auth)
2. âœ… Authentication (valid/invalid keys)
3. âœ… Rate limiting (rapid requests)
4. âœ… Structured logging (request_id tracking)
5. âœ… Prometheus metrics (validation)
6. âœ… Error handling (Sentry integration)

### Expected Output

```
================================================================================
                        TIER 1 FEATURE TESTING SUMMARY                        
================================================================================

âœ“ Public Endpoints
âœ“ Authentication
âœ“ Rate Limiting
âœ“ Structured Logging
âœ“ Prometheus Metrics
âœ“ Error Handling

Result: 6/6 tests passed

ðŸŽ‰ ALL TIER 1 FEATURES OPERATIONAL! ðŸŽ‰
```

---

## ðŸš€ Deployment

### Cloud Run Deployment

```bash
# Build and deploy
cd ai-worker
gcloud builds submit --tag gcr.io/PROJECT_ID/omni-ai-worker:tier1
gcloud run deploy omni-ai-worker \
  --image gcr.io/PROJECT_ID/omni-ai-worker:tier1 \
  --region europe-west1 \
  --platform managed \
  --allow-unauthenticated \
  --set-env-vars SENTRY_DSN=$SENTRY_DSN,ENVIRONMENT=production \
  --memory 2Gi --cpu 2
```

### Docker Local Testing

```bash
# Build
docker build -t omni-ai-worker:tier1 .

# Run with environment
docker run -p 8080:8080 \
  -e SENTRY_DSN=$SENTRY_DSN \
  -e MASTER_API_KEY=$MASTER_API_KEY \
  -e REDIS_HOST=host.docker.internal \
  omni-ai-worker:tier1
```

---

## ðŸ“ˆ Monitoring Setup

### 1. Prometheus

```bash
# prometheus.yml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'omni-ai-worker'
    static_configs:
      - targets: ['omni-ai-worker.run.app:443']
    scheme: https
    metrics_path: '/metrics'
```

### 2. Grafana Dashboards

Import these panels:
- **Request Rate**: `rate(api_requests_total[5m])`
- **Error Rate**: `rate(api_errors_total[5m]) / rate(api_requests_total[5m])`
- **P95 Latency**: `histogram_quantile(0.95, api_request_duration_seconds_bucket)`
- **Active Requests**: `api_active_requests`
- **Model Calls**: `rate(model_requests_total[5m])`

### 3. Alerting Rules

```yaml
groups:
  - name: omni-ai-worker
    rules:
      - alert: HighErrorRate
        expr: rate(api_errors_total[5m]) > 0.1
        for: 5m
        annotations:
          summary: "High error rate detected"
      
      - alert: HighLatency
        expr: histogram_quantile(0.95, api_request_duration_seconds_bucket) > 5
        for: 5m
        annotations:
          summary: "API latency P95 > 5s"
```

---

## ðŸ”§ Troubleshooting

### Issue: Sentry not capturing errors

**Check**:
```bash
# Verify DSN is set
echo $SENTRY_DSN

# Check logs for Sentry init
grep "Sentry initialized" logs.json
```

### Issue: Rate limiting not working

**Check**:
```bash
# Verify slowapi is installed
pip show slowapi

# Check if limiter is added to app
grep "app.state.limiter" main.py
```

### Issue: Metrics endpoint returns 404

**Check**:
```bash
# Verify prometheus_client installed
pip show prometheus-client

# Test metrics generation
python -c "from middleware.prometheus_metrics import get_metrics; print(len(get_metrics()))"
```

### Issue: Logs not structured

**Check**:
```bash
# Verify logger import
grep "from utils.structured_logging import" main.py

# Test logger output
python -c "from utils.structured_logging import get_logger; logger = get_logger('test'); logger.info('test')"
```

---

## ðŸ“š Next Steps

After TIER 1 is operational:

### TIER 2: Performance & Scalability
- Redis caching layer
- Database connection pooling
- Async task queue (Celery)

### TIER 3: Advanced AI Features
- Model versioning & A/B testing
- AutoML hyperparameter optimization
- Multi-modal AI support

### TIER 4: Security & Compliance
- Data encryption at rest
- GDPR compliance tools
- Audit logging

---

## ðŸ’¡ Best Practices

1. **Always use API keys** in production
2. **Monitor metrics daily** via Grafana
3. **Set up Sentry alerts** for critical errors
4. **Review logs** for performance bottlenecks
5. **Test rate limits** before deploying
6. **Keep dependencies updated** for security patches

---

## ðŸ“ž Support

- **Issues**: Check logs with `grep ERROR logs.json`
- **Performance**: Review `/metrics` endpoint
- **Errors**: Check Sentry dashboard
- **Questions**: See `ENHANCEMENT_ROADMAP.md`

---

**TIER 1 Implementation Complete! ðŸŽ‰**

Your AI Worker now has production-grade:
- âœ… Monitoring (Prometheus)
- âœ… Logging (Structured JSON)
- âœ… Security (API Keys + Rate Limiting)
- âœ… Error Tracking (Sentry)

**Estimated Impact**: 80% reduction in MTTR, enterprise-ready operations
