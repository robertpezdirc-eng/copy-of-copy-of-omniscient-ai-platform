steps:
  - name: 'gcr.io/cloud-builders/docker'
    args:
      - build
      - -t
      - europe-west1-docker.pkg.dev/${_PROJECT_ID}/omni/advanced-ai:${_TAG}
      - -f
      - Dockerfile.backend
      - .
    timeout: 1800s

  - name: 'gcr.io/cloud-builders/docker'
    args:
      - push
      - europe-west1-docker.pkg.dev/${_PROJECT_ID}/omni/advanced-ai:${_TAG}

  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: gcloud
    args:
      - run
      - deploy
      - ${_SERVICE}
      - --image=europe-west1-docker.pkg.dev/${_PROJECT_ID}/omni/advanced-ai:${_TAG}
      - --region=${_REGION}
      - --platform=managed
      - --allow-unauthenticated
      - --port=8080
      - --memory=${_MEMORY}
      - --cpu=${_CPU}
      - --max-instances=${_MAX_INSTANCES}
      - --min-instances=${_MIN_INSTANCES}
      - --concurrency=${_CONCURRENCY}
      - --set-env-vars=RUN_AS_INTERNAL=1,AI_FEATURE_FLAGS=model_versioning|ab_testing|automl|multimodal,ACTIVE_MODEL_VERSION=${_ACTIVE_MODEL_VERSION},CANARY_MODEL_VERSION=${_CANARY_MODEL_VERSION},CANARY_TRAFFIC_PERCENT=${_CANARY_TRAFFIC_PERCENT},AUTOML_DATASET_BUCKET=${_AUTOML_DATASET_BUCKET},MULTIMODAL_ENABLED=${_MULTIMODAL_ENABLED},TRACE_SAMPLING_RATE=${_TRACE_SAMPLING_RATE}
      - --update-secrets=OPENAI_API_KEY=${_OPENAI_API_SECRET}
      - --labels=service=advanced-ai,segment=ml-platform

images:
  - europe-west1-docker.pkg.dev/${_PROJECT_ID}/omni/advanced-ai:${_TAG}

options:
  machineType: E2_HIGHCPU_8
  diskSizeGb: 100

timeout: 3600s

# Provide sane defaults so gcloud recognizes custom substitutions; callers should override as needed.
substitutions:
  _PROJECT_ID: refined-graph-471712-n9
  _TAG: latest
  _SERVICE: advanced-ai-service
  _REGION: europe-west1
  _MEMORY: 4Gi
  _CPU: '2'
  _MAX_INSTANCES: '5'
  _MIN_INSTANCES: '1'
  _CONCURRENCY: '80'
  _ACTIVE_MODEL_VERSION: v1
  _CANARY_MODEL_VERSION: v1
  _CANARY_TRAFFIC_PERCENT: '0'
  _AUTOML_DATASET_BUCKET: gs://omni-automl-datasets
  _MULTIMODAL_ENABLED: "true"
  _TRACE_SAMPLING_RATE: '0.1'
  _OPENAI_API_SECRET: OPENAI_API_KEY:latest

# Expected substitutions when running Cloud Build:
#  _PROJECT_ID            -> GCP project id (refined-graph-471712-n9)
#  _TAG                   -> Image tag (e.g. $SHORT_SHA)
#  _SERVICE               -> Cloud Run service name (advanced-ai-service)
#  _REGION                -> Deployment region (europe-west1)
#  _MEMORY                -> Cloud Run memory allocation (e.g. 4Gi)
#  _CPU                   -> Cloud Run CPU allocation (e.g. 2)
#  _MAX_INSTANCES         -> Max Cloud Run instances (e.g. 5)
#  _MIN_INSTANCES         -> Min Cloud Run instances (e.g. 1 for warm canary)
#  _CONCURRENCY           -> Requests per instance (e.g. 80)
#  _ACTIVE_MODEL_VERSION  -> Production model version (e.g. v1)
#  _CANARY_MODEL_VERSION  -> Canary model version (e.g. v2)
#  _CANARY_TRAFFIC_PERCENT-> Integer 0-50 controlling canary traffic split
#  _AUTOML_DATASET_BUCKET -> Bucket or dataset path for AutoML jobs
#  _MULTIMODAL_ENABLED    -> true/false flag
#  _TRACE_SAMPLING_RATE   -> Float 0-1 for OpenTelemetry sampling (e.g. 0.1)
#  _OPENAI_API_SECRET     -> Secret manager reference (e.g. OPENAI_API_KEY:latest)
#  (Add flags like --set-cloudsql-instances or --vpc-connector via trigger if needed.)
