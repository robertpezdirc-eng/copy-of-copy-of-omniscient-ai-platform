#!/usr/bin/env python3
"""
OMNI Self-Building System
AI-driven automated code generation, analysis, testing, and deployment

This system enhances the existing generators with AI-powered self-building capabilities:
- AI Code Generation using Vertex AI/Gemini
- Automated quality analysis and improvement
- Self-healing code fixes
- Integrated build and deployment pipeline
- GCP integration for seamless operations

Author: OMNI Self-Building System
Version: 1.0.0
"""

import asyncio
import json
import os
import sys
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Import existing tools
from omni_development_tools import omni_code_analyzer, omni_test_generator, omni_refactoring_tool
from omni_documentation_tools import omni_document_generator
from vr_project_generator import OmniVRProjectGenerator

# GCP and AI integrations
try:
    import google.generativeai as genai
    from google.cloud import aiplatform
    from google.oauth2 import service_account
except ImportError:
    print("Warning: Google AI libraries not installed. Install with: pip install google-generativeai google-cloud-aiplatform")

class OmniAICodeGenerator:
    """AI-powered code generation using Vertex AI/Gemini"""

    def __init__(self, project_id: str = None, region: str = "europe-west1"):
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT', 'omni-singularity-project')
        self.region = region
        self.model_name = "gemini-2.0-flash"  # Updated to latest model
        self.logger = self._setup_logging()

        # Initialize Vertex AI
        self._initialize_vertex_ai()

    def _setup_logging(self) -> logging.Logger:
        """Setup logging"""
        logger = logging.getLogger('OmniAICodeGenerator')
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.FileHandler('omni_ai_code_generator.log', encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def _initialize_vertex_ai(self):
        """Initialize Vertex AI"""
        try:
            # Set up credentials
            credentials_file = os.getenv('GOOGLE_APPLICATION_CREDENTIALS', 'service_account.json')
            if os.path.exists(credentials_file):
                credentials = service_account.Credentials.from_service_account_file(credentials_file)
                aiplatform.init(project=self.project_id, location=self.region, credentials=credentials)
            else:
                aiplatform.init(project=self.project_id, location=self.region)

            # Configure Gemini
            genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
            self.model = genai.GenerativeModel(self.model_name)

            self.logger.info("Vertex AI and Gemini initialized successfully")

        except Exception as e:
            self.logger.error(f"Failed to initialize Vertex AI: {e}")
            self.model = None

    async def generate_code(self, prompt: str, language: str = "python",
                           context: Dict[str, Any] = None) -> Dict[str, Any]:
        """Generate code using AI"""
        result = {
            "status": "failed",
            "generated_code": "",
            "explanation": "",
            "suggestions": [],
            "error": None
        }

        if not self.model:
            result["error"] = "AI model not initialized"
            return result

        try:
            # Enhanced prompt with context
            full_prompt = f"""
            Generate high-quality {language} code based on the following requirements:

            {prompt}

            Context:
            {json.dumps(context or {}, indent=2)}

            Requirements:
            - Follow best practices for {language}
            - Include proper error handling
            - Add docstrings and comments
            - Ensure security and performance
            - Make it production-ready

            Generate complete, runnable code with explanations.
            """

            response = self.model.generate_content(full_prompt)

            if response and response.text:
                result["generated_code"] = response.text
                result["status"] = "success"

                # Extract explanation and suggestions
                result["explanation"] = self._extract_explanation(response.text)
                result["suggestions"] = self._extract_suggestions(response.text)

                self.logger.info(f"Code generated successfully for prompt: {prompt[:50]}...")

            else:
                result["error"] = "No response from AI model"

        except Exception as e:
            self.logger.error(f"Error generating code: {e}")
            result["error"] = str(e)

        return result

    def _extract_explanation(self, response_text: str) -> str:
        """Extract explanation from AI response"""
        # Simple extraction - look for explanation section
        lines = response_text.split('\n')
        explanation_lines = []

        in_explanation = False
        for line in lines:
            if 'explanation' in line.lower() or 'why' in line.lower() or 'because' in line.lower():
                in_explanation = True
            if in_explanation:
                explanation_lines.append(line)
            if line.strip() == '' and in_explanation:
                break

        return '\n'.join(explanation_lines) if explanation_lines else "Code generated based on requirements"

    def _extract_suggestions(self, response_text: str) -> List[str]:
        """Extract suggestions from AI response"""
        suggestions = []

        # Look for suggestion patterns
        lines = response_text.split('\n')
        for line in lines:
            if any(keyword in line.lower() for keyword in ['suggest', 'recommend', 'consider', 'note']):
                suggestions.append(line.strip())

        return suggestions[:5]  # Limit to 5 suggestions

class OmniSelfBuildingEngine:
    """Main self-building engine that orchestrates all tools"""

    def __init__(self, project_id: str = None, region: str = "europe-west1"):
        self.project_id = project_id or os.getenv('GOOGLE_CLOUD_PROJECT', 'omni-singularity-project')
        self.region = region
        self.start_time = time.time()
        self.logger = self._setup_logging()

        # Initialize components
        self.ai_generator = OmniAICodeGenerator(self.project_id, self.region)
        self.vr_generator = OmniVRProjectGenerator()
        self.build_history: List[Dict[str, Any]] = []

        # Load configuration
        self.config = self._load_config()

    def _setup_logging(self) -> logging.Logger:
        """Setup logging"""
        logger = logging.getLogger('OmniSelfBuildingEngine')
        logger.setLevel(logging.INFO)
        if not logger.handlers:
            handler = logging.FileHandler('omni_self_building.log', encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        return logger

    def _load_config(self) -> Dict[str, Any]:
        """Load self-building configuration"""
        config_file = "omni_self_building_config.json"
        default_config = {
            "auto_analyze": True,
            "auto_generate_tests": True,
            "auto_generate_docs": True,
            "auto_refactor": True,
            "auto_deploy": False,
            "quality_threshold": 80.0,
            "max_iterations": 3,
            "supported_languages": ["python", "javascript", "html", "css"],
            "deployment_target": "cloudrun"
        }

        try:
            if os.path.exists(config_file):
                with open(config_file, 'r') as f:
                    return json.load(f)
            else:
                # Save default config
                with open(config_file, 'w') as f:
                    json.dump(default_config, f, indent=2)
                return default_config
        except Exception as e:
            self.logger.error(f"Error loading config: {e}")
            return default_config

    async def self_build_project(self, prompt: str, project_type: str = "webapp",
                                target_directory: str = ".") -> Dict[str, Any]:
        """Main self-building function"""
        build_result = {
            "status": "started",
            "timestamp": datetime.now().isoformat(),
            "prompt": prompt,
            "project_type": project_type,
            "steps": [],
            "generated_files": [],
            "analysis_results": {},
            "test_results": {},
            "deployment_status": None,
            "error": None
        }

        try:
            self.logger.info(f"Starting self-build for prompt: {prompt[:50]}...")

            # Step 1: Generate code using AI
            step_result = await self._step_generate_code(prompt, project_type, build_result)
            build_result["steps"].append(step_result)

            if step_result["status"] != "success":
                build_result["status"] = "failed"
                build_result["error"] = step_result["error"]
                return build_result

            # Step 2: Analyze generated code
            if self.config["auto_analyze"]:
                step_result = await self._step_analyze_code(build_result["generated_files"], build_result)
                build_result["steps"].append(step_result)
                build_result["analysis_results"] = step_result.get("data", {})

            # Step 3: Generate tests
            if self.config["auto_generate_tests"]:
                step_result = await self._step_generate_tests(build_result["generated_files"], build_result)
                build_result["steps"].append(step_result)
                build_result["test_results"] = step_result.get("data", {})

            # Step 4: Generate documentation
            if self.config["auto_generate_docs"]:
                step_result = await self._step_generate_docs(build_result["generated_files"], build_result)
                build_result["steps"].append(step_result)

            # Step 5: Refactor if needed
            if self.config["auto_refactor"]:
                step_result = await self._step_refactor_code(build_result["generated_files"], build_result)
                build_result["steps"].append(step_result)

            # Step 6: Deploy if configured
            if self.config["auto_deploy"]:
                step_result = await self._step_deploy_project(build_result)
                build_result["steps"].append(step_result)
                build_result["deployment_status"] = step_result.get("status", "unknown")

            build_result["status"] = "completed"
            self.logger.info("Self-build completed successfully")

        except Exception as e:
            self.logger.error(f"Self-build failed: {e}")
            build_result["status"] = "failed"
            build_result["error"] = str(e)

        # Save build history
        self._save_build_history(build_result)

        return build_result

    async def _step_generate_code(self, prompt: str, project_type: str, build_result: Dict) -> Dict[str, Any]:
        """Step 1: Generate code using AI"""
        step = {"step": "generate_code", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            if project_type == "vr":
                # Use VR generator
                project_data = await self.vr_generator.generate_vr_project(prompt, "game")
                if project_data["status"] == "completed":
                    # Save generated files
                    project_dir = self.vr_generator.save_project(project_data)
                    build_result["generated_files"] = [os.path.join(project_dir, f) for f in project_data.get("files", {})]
                    step["data"] = {"project_dir": project_dir, "files": project_data["files"]}
                else:
                    step["status"] = "failed"
                    step["error"] = project_data.get("error", "VR generation failed")
                    return step

            else:
                # Use AI code generator
                context = {"project_type": project_type, "target_directory": build_result.get("target_directory", ".")}
                generation_result = await self.ai_generator.generate_code(prompt, "python", context)

                if generation_result["status"] == "success":
                    # Save generated code
                    code_file = os.path.join(build_result.get("target_directory", "."), f"generated_{project_type}.py")
                    with open(code_file, 'w') as f:
                        f.write(generation_result["generated_code"])

                    build_result["generated_files"] = [code_file]
                    step["data"] = generation_result
                else:
                    step["status"] = "failed"
                    step["error"] = generation_result["error"]
                    return step

            step["status"] = "success"

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    async def _step_analyze_code(self, files: List[str], build_result: Dict) -> Dict[str, Any]:
        """Step 2: Analyze generated code"""
        step = {"step": "analyze_code", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            analysis_data = {}

            for file_path in files:
                if os.path.exists(file_path):
                    analysis = omni_code_analyzer.analyze_file(file_path)
                    if analysis:
                        analysis_data[file_path] = omni_code_analyzer._analysis_to_dict(analysis)

                        # Check quality threshold
                        quality_score = analysis.quality_score
                        if quality_score < self.config["quality_threshold"]:
                            step["warnings"] = step.get("warnings", []) + [f"Low quality score ({quality_score}) for {file_path}"]

            step["status"] = "success"
            step["data"] = analysis_data

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    async def _step_generate_tests(self, files: List[str], build_result: Dict) -> Dict[str, Any]:
        """Step 3: Generate tests for generated code"""
        step = {"step": "generate_tests", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            test_data = {}

            for file_path in files:
                if file_path.endswith('.py'):
                    test_result = omni_test_generator.generate_unit_tests(file_path)
                    test_data[file_path] = test_result

                    # Save generated tests
                    if test_result.get("test_content"):
                        test_file = test_result["test_file"]
                        with open(test_file, 'w') as f:
                            f.write(test_result["test_content"])

            step["status"] = "success"
            step["data"] = test_data

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    async def _step_generate_docs(self, files: List[str], build_result: Dict) -> Dict[str, Any]:
        """Step 4: Generate documentation"""
        step = {"step": "generate_docs", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            doc_data = {}

            for file_path in files:
                if file_path.endswith('.py'):
                    # Generate API docs
                    doc_result = omni_document_generator.generate_api_documentation(os.path.dirname(file_path), "markdown")
                    doc_data[file_path] = doc_result

            step["status"] = "success"
            step["data"] = doc_data

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    async def _step_refactor_code(self, files: List[str], build_result: Dict) -> Dict[str, Any]:
        """Step 5: Refactor code if needed"""
        step = {"step": "refactor_code", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            refactor_data = {}

            for file_path in files:
                suggestions = omni_refactoring_tool.suggest_refactoring(file_path)
                refactor_data[file_path] = suggestions

                # Apply high-priority refactorings if any
                if suggestions.get("priority_refactorings"):
                    step["applied_refactorings"] = len(suggestions["priority_refactorings"])

            step["status"] = "success"
            step["data"] = refactor_data

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    async def _step_deploy_project(self, build_result: Dict) -> Dict[str, Any]:
        """Step 6: Deploy project to GCP"""
        step = {"step": "deploy_project", "status": "running", "timestamp": datetime.now().isoformat()}

        try:
            # Use existing deployment script
            deployment_target = self.config["deployment_target"]

            if deployment_target == "cloudrun":
                # Run Cloud Run deployment script
                script_path = "scripts/redeploy_cloudrun_all.ps1"
                if os.path.exists(script_path):
                    # Note: This would need to be adapted for cross-platform or use Python equivalent
                    step["note"] = "Deployment script available, manual execution recommended"
                else:
                    step["error"] = "Deployment script not found"

            step["status"] = "success"

        except Exception as e:
            step["status"] = "failed"
            step["error"] = str(e)

        return step

    def _save_build_history(self, build_result: Dict):
        """Save build history to file"""
        history_file = "omni_build_history.json"

        try:
            if os.path.exists(history_file):
                with open(history_file, 'r') as f:
                    history = json.load(f)
            else:
                history = []

            history.append(build_result)

            # Keep only last 10 builds
            history = history[-10:]

            with open(history_file, 'w') as f:
                json.dump(history, f, indent=2)

        except Exception as e:
            self.logger.error(f"Error saving build history: {e}")

# CLI Interface
async def main():
    """Main CLI function"""
    print("ğŸš€ OMNI Self-Building System")
    print("=" * 40)
    print("AI-powered automated code generation and deployment")
    print()

    if len(sys.argv) < 2:
        print("Usage: python omni_self_building_system.py 'Your project description'")
        print("Example: python omni_self_building_system.py 'Create a web app for task management'")
        sys.exit(1)

    prompt = sys.argv[1]
    project_type = sys.argv[2] if len(sys.argv) > 2 else "webapp"

    # Initialize engine
    engine = OmniSelfBuildingEngine()

    print(f"ğŸ¯ Building project from prompt: {prompt}")
    print(f"ğŸ“ Project type: {project_type}")
    print()

    # Run self-build
    result = await engine.self_build_project(prompt, project_type)

    # Display results
    print(f"âœ… Build Status: {result['status']}")
    print(f"ğŸ“Š Steps Completed: {len(result['steps'])}")

    if result.get("generated_files"):
        print(f"ğŸ“„ Files Generated: {len(result['generated_files'])}")
        for file in result["generated_files"]:
            print(f"   - {file}")

    if result.get("analysis_results"):
        print(f"ğŸ” Code Analysis: Completed")

    if result.get("test_results"):
        print(f"ğŸ§ª Tests Generated: Completed")

    if result.get("error"):
        print(f"âŒ Error: {result['error']}")

    print()
    print("ğŸ‰ Self-building process completed!")

if __name__ == "__main__":
    asyncio.run(main())